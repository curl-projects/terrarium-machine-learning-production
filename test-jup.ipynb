{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import openai\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "import prisma\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Search String Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\"\n",
    "\n",
    "search_string = 'Responsive Whiteboards'\n",
    "search_vector = get_embedding(search_string, engine=\"text-search-babbage-query-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 100\n",
    "\n",
    "url = \"https://terrarium-1ce80e9.svc.us-west1-gcp.pinecone.io/query\"\n",
    "data = {\n",
    "    \"vector\": search_vector,\n",
    "    \"includeValues\": True,\n",
    "    \"topK\": top_k\n",
    "}\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Api-Key\": os.environ['PINECONE_API_KEY']\n",
    "}\n",
    "\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "pinecone_vectors = response.json()\n",
    "filtered_vectors = list(filter(lambda x: x[\"score\"] > 0.25, pinecone_vectors['matches']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 10\n",
    "\n",
    "vector_matrix = pd.DataFrame(filtered_vectors)\n",
    "\n",
    "matrix = np.vstack(vector_matrix['values'].values)\n",
    "assert matrix.shape[1] == 2048\n",
    "kmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", random_state=42, n_init=10)\n",
    "kmeans.fit(matrix)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_vectors = [{\"id\": i[\"id\"], \"score\": i[\"score\"], \"cluster\": labels[idx]} for idx, i in enumerate(filtered_vectors)]\n",
    "\n",
    "tmp = defaultdict(list)\n",
    "for item in stripped_vectors:\n",
    "    tmp[item['cluster']].append([item['id']])\n",
    "output = dict(tmp.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = dict(zip(map(int, output.keys()), list(map(lambda x: list(map(lambda y: y[0], x)), output.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cluster-ids.json', \"w\") as outfile:\n",
    "    json.dump(final_output, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All Feature Requests By Ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./cluster-frs.json')\n",
    "data = json.load(f)\n",
    "\n",
    "fr_data = {k: list(map(json.loads, v)) for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, data in fr_data.items():\n",
    "    print(cluster)\n",
    "    print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Cluster Content [Local Clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Collapsing whiteboards',\n",
       " '1. Multiple panes/whiteboards',\n",
       " '1. A whiteboard specifically for templates',\n",
       " '2. Share whiteboard with colleagues',\n",
       " '2. Great for using images on whiteboards',\n",
       " '2. Whiteboards with multiple cards',\n",
       " '2. Map showing recently edited whiteboards',\n",
       " '2. A hotkey to quickly access the whiteboard.',\n",
       " '2. An animation feature for whiteboards.',\n",
       " '1. More \"snap to grid\" on the whiteboard',\n",
       " '2. A whiteboard template with specific spacing/layout']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x['fr'] for x in fr_data['7']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_prompt_data(unsorted_input_list):\n",
    "    input_list = sorted(unsorted_input_list, key=lambda x: len(x))\n",
    "    \n",
    "    char_count = 0\n",
    "    output_str = \"\"\n",
    "    for fr in input_list:\n",
    "        if (char_count + len(fr) < 1800):\n",
    "            output_str += \"\\n\" + fr\n",
    "            char_count += len(fr)\n",
    "        else:\n",
    "            break\n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_local_cluster(input_list, feature_title, top_p=0.15):\n",
    "    x = shorten_prompt_data(input_list)\n",
    "    prompt = f\"\"\"\n",
    "        What are three things many of these message request about the feature '{feature_title}'. \n",
    "        Use only nouns and describe each one in fewer than five words. \n",
    "        Provide your answer in the form of a Python list, and don't include any newline characters.\n",
    "        Include no other commentary. Do not add a newline before replying.\n",
    "        Feature Requests: {x}\n",
    "    \"\"\"\n",
    "    res = openai.Completion.create(model=\"text-davinci-002\", \n",
    "                                        prompt=prompt,\n",
    "                                        top_p=top_p, \n",
    "                                        max_tokens=200)\n",
    "    return res['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = analyse_local_cluster([x['fr'] for x in fr_data['7']], 'Responsive, Interactive Whiteboards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Collapsing whiteboards', 'Multiple panes/whiteboards', 'Whiteboards with multiple cards']\""
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Cluster Content (Global Clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_fr_data = [item for sublist in fr_data.values() for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fr_id': '1004812227775307786-1853161927541104386',\n",
       " 'message_id': '1004812227775307786',\n",
       " 'message': \"hi alan. partially. but being able to expand more than one whiteboard in the sidebar will show more, at-a-glance, than breadcrumbs alone. breadcrumbs show me where i've been, but the sidebar will show me where i might need to go next.\",\n",
       " 'created_at': '2022-08-04T18:05:03.610000+00:00',\n",
       " 'author': 'Sams_Here',\n",
       " 'label': 'Request',\n",
       " 'fr': '1. The ability to expand more than one whiteboard in the sidebar.',\n",
       " 'kmeans_labels': 4,\n",
       " 'userId': '110421822788553907926',\n",
       " 'user': None,\n",
       " 'features': None}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_fr_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = defaultdict(list)\n",
    "for item in flat_fr_data:\n",
    "    tmp[str(item['kmeans_labels'])].append(item['fr'])\n",
    "kmeans_output = dict(tmp.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_kmeans_cluster(input_list, top_p):\n",
    "    x = shorten_prompt_data(input_list)\n",
    "    res = openai.Completion.create(model=\"text-davinci-002\", \n",
    "                                    prompt=\"What are three things many of these feature requests asking for about whiteboards. Answer in the form Common Theme: {x} and use only nouns. List three common themes. \\n Feature Requests:\" + x, \n",
    "                                    top_p=top_p, \n",
    "                                    max_tokens=200)\n",
    "    return res['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nCommon Theme: Zooming\\nCommon Theme: Positioning of cards\\nCommon Theme: Presentation'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyse_kmeans_cluster(kmeans_output['41'][:10], top_p=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"/Users/finnmacken/Desktop/TerrariumV2/machine-learning-pipeline/test-dataset.json\")\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_matrix = pd.DataFrame(data)\n",
    "matrix = np.vstack(vector_matrix['values'].values)\n",
    "assert matrix.shape[1] == 2048\n",
    "kmeans = KMeans(n_clusters=20, init=\"k-means++\", random_state=42, n_init=10)\n",
    "kmeans.fit(matrix)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_vectors = [{\"id\": i[\"id\"], \"score\": i[\"score\"], \"cluster\": labels[idx]} for idx, i in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = defaultdict(list)\n",
    "for item in filtered_vectors:\n",
    "    tmp[item['cluster']].append([item['id']])\n",
    "output = dict(tmp.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, embeddings in output.items():\n",
    "    new_embeddings = [{\n",
    "                    \"featureId_featureRequestId\": {\n",
    "                        \"featureId\": 17,\n",
    "                        \"featureRequestId\": embedding[0],\n",
    "                    }\n",
    "                } for embedding in embeddings]\n",
    "    print(new_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
